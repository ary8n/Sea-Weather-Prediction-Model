{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bvLSZrsK4onO",
        "outputId": "42664f66-d887-416a-84bc-9703207d6482"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded dry blub temperature.csv successfully! Shape: (145, 1)\n",
            "✅ Loaded potential temperature.csv successfully! Shape: (17473, 1)\n",
            "✅ Loaded sea surface temperature.csv successfully! Shape: (20384, 5)\n",
            "✅ Loaded surface heigh.csv successfully! Shape: (20384, 5)\n",
            "✅ Loaded surface_height.csv successfully! Shape: (20384, 5)\n",
            "✅ Loaded vertical velocity at t points.csv successfully! Shape: (17473, 1)\n",
            "\n",
            "📂 **Performing LSTM on dry blub temperature.csv**\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: nan\n",
            "✅ Test Loss: nan\n",
            "\n",
            "📂 **Performing LSTM on potential temperature.csv**\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan\n",
            "✅ Test Loss: nan\n",
            "\n",
            "📂 **Performing LSTM on sea surface temperature.csv**\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: nan\n",
            "✅ Test Loss: nan\n",
            "\n",
            "📂 **Performing LSTM on surface heigh.csv**\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan\n",
            "✅ Test Loss: nan\n",
            "\n",
            "📂 **Performing LSTM on surface_height.csv**\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m892/892\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan\n",
            "✅ Test Loss: nan\n",
            "\n",
            "📂 **Performing LSTM on vertical velocity at t points.csv**\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/50\n",
            "\u001b[1m764/764\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: nan - val_loss: nan\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: nan\n",
            "✅ Test Loss: nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-46f79ed74008>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Compute R² Score and MAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# List of CSV files\n",
        "csv_files = [\n",
        "    \"dry blub temperature.csv\",\n",
        "    \"potential temperature.csv\",\n",
        "    \"sea surface temperature.csv\",\n",
        "    \"surface heigh.csv\",\n",
        "    \"surface_height.csv\",\n",
        "    \"vertical velocity at t points.csv\"\n",
        "]\n",
        "\n",
        "# Dictionary to store DataFrames\n",
        "dfs = {}\n",
        "\n",
        "# Load datasets\n",
        "for file in csv_files:\n",
        "    if os.path.exists(file):\n",
        "        try:\n",
        "            df = pd.read_csv(file, delimiter=\",\", encoding=\"utf-8\", on_bad_lines=\"skip\", engine=\"python\", skiprows=8)  # Skip metadata\n",
        "\n",
        "            # Convert all columns (except datetime) to numeric, forcing errors to NaN\n",
        "            for col in df.columns:\n",
        "                if col not in [\"DATETIME\", \"TIME\"]:  # Exclude time-related columns\n",
        "                    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "            # Replace -1.E+34 (error values) with NaN\n",
        "            df.replace([-1e+34, \"-1.E+34\", -1.0e+34, \"-1.000000e+34\"], np.nan, inplace=True)\n",
        "\n",
        "            dfs[file] = df\n",
        "            print(f\"✅ Loaded {file} successfully! Shape: {df.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error loading {file}: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Warning: {file} not found!\")\n",
        "\n",
        "# Function to perform LSTM on each dataset\n",
        "def perform_lstm(dfs):\n",
        "    for file, df in dfs.items():\n",
        "        print(f\"\\n📂 **Performing LSTM on {file}**\")\n",
        "\n",
        "        # Select numeric columns\n",
        "        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "        if not numeric_cols.empty:\n",
        "            # Scale data\n",
        "            scaler = MinMaxScaler()\n",
        "            scaled_data = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "            # Reshape data for LSTM\n",
        "            sequence_length = 10\n",
        "            X = []\n",
        "            y = []\n",
        "            for i in range(sequence_length, len(scaled_data)):\n",
        "                X.append(scaled_data[i-sequence_length:i])\n",
        "                y.append(scaled_data[i])\n",
        "\n",
        "            X = np.array(X)\n",
        "            y = np.array(y)\n",
        "\n",
        "            # Split data into training and testing sets\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=False)\n",
        "\n",
        "            # Reshape for LSTM input\n",
        "            X_train = X_train.reshape(X_train.shape[0], sequence_length, scaled_data.shape[1])\n",
        "            X_test = X_test.reshape(X_test.shape[0], sequence_length, scaled_data.shape[1])\n",
        "\n",
        "            # Build LSTM model\n",
        "            model = Sequential([\n",
        "                LSTM(units=50, return_sequences=True, input_shape=(sequence_length, scaled_data.shape[1])),\n",
        "                LSTM(units=50),\n",
        "                Dense(scaled_data.shape[1])\n",
        "            ])\n",
        "\n",
        "            # Compile model\n",
        "            model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "            # Train model\n",
        "            model.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "            # Evaluate model\n",
        "            loss = model.evaluate(X_test, y_test)\n",
        "            print(f\"✅ Test Loss: {loss}\")\n",
        "        else:\n",
        "            print(f\"⚠️ No numeric columns found in {file}.\")\n",
        "\n",
        "# Perform LSTM on each dataset\n",
        "perform_lstm(dfs)\n",
        "\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Compute R² Score and MAE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Test Loss (MSE): {loss:.4f}\")\n",
        "print(f\"📊 R² Score: {r2:.4f}\")\n",
        "print(f\"📉 Mean Absolute Error (MAE): {mae:.4f}\")\n"
      ]
    }
  ]
}