{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "for file in all_files:\n",
        "    try:\n",
        "        df = pd.read_csv(file, delimiter=\",\", encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
        "        print(f\"✅ Loaded {file} successfully! Shape: {df.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading {file}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c7abgriKujc",
        "outputId": "89ee8786-0d52-41e7-a76f-fbf38a35a8af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/surface_height.csv successfully! Shape: (7, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/zonal current.csv successfully! Shape: (8, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/vertical velocity at t points.csv successfully! Shape: (8, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/sea surface temperature.csv successfully! Shape: (7, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/dry blub temperature.csv successfully! Shape: (8, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/potential temperature.csv successfully! Shape: (8, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/surface heigh.csv successfully! Shape: (7, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/salinity.csv successfully! Shape: (8, 1)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/surface height on  t cell.csv successfully! Shape: (7, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set pandas float format to prevent scientific notation\n",
        "pd.set_option('display.float_format', '{:.13f}'.format)\n",
        "\n",
        "# File paths (update if needed)\n",
        "file_paths = [\n",
        "    \"/content/drive/MyDrive/OceansLSTM/surface_height.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/zonal current.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/vertical velocity at t points.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/sea surface temperature.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/dry blub temperature.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/potential temperature.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/surface heigh.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/salinity.csv\",\n",
        "    \"/content/drive/MyDrive/OceansLSTM/surface height on  t cell.csv\",\n",
        "]\n",
        "\n",
        "# Dictionary to store processed DataFrames\n",
        "dfs = {}\n",
        "\n",
        "for file in file_paths:\n",
        "    try:\n",
        "        # Extract filename (without extension) for column naming\n",
        "        file_name = file.split(\"/\")[-1].replace(\".csv\", \"\").replace(\" \", \"_\")\n",
        "\n",
        "        # Auto-detect delimiter and load CSV\n",
        "        df = pd.read_csv(file, skiprows=14, header=None, sep=None, engine='python')\n",
        "\n",
        "        # Replace error values with NaN\n",
        "        df.replace(['-999', '99999', 'NaN', 'Err', 'error', 'inf', '-inf', ''], np.nan, inplace=True)\n",
        "\n",
        "        # Check column count and assign appropriate names\n",
        "        if df.shape[1] == 6:\n",
        "            df.columns = ['DATETIME', 'TIME', 'LON', 'LAT', 'DEP', file_name]\n",
        "            df.drop(['DATETIME', 'DEP'], axis=1, inplace=True)  # Drop unwanted columns\n",
        "        elif df.shape[1] == 5:\n",
        "            df.columns = ['DATETIME', 'TIME', 'LON', 'LAT', file_name]\n",
        "            df.drop(['DATETIME'], axis=1, inplace=True)\n",
        "        else:\n",
        "            print(f\"⚠️ Skipping {file} due to unexpected format.\")\n",
        "            continue  # Skip files with incorrect structure\n",
        "\n",
        "        # Store the cleaned DataFrame\n",
        "        dfs[file] = df\n",
        "        print(f\"✅ Loaded {file} | Shape: {df.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading {file}: {e}\")\n",
        "\n",
        "# Merge all datasets on TIME, LON, LAT\n",
        "merged_df = None\n",
        "for file, df in dfs.items():\n",
        "    if merged_df is None:\n",
        "        merged_df = df  # First dataset\n",
        "    else:\n",
        "        merged_df = pd.merge(merged_df, df, on=['TIME', 'LON', 'LAT'], how='outer')\n",
        "\n",
        "# Define error values to replace\n",
        "error_values = [-9999999999999999455752309870428160.0000000000000, -999999.0, -9999.0]\n",
        "\n",
        "# Replace error values with NaN\n",
        "merged_df.replace(error_values, np.nan, inplace=True)\n",
        "\n",
        "# Fill missing values\n",
        "merged_df = merged_df.bfill().ffill().interpolate()\n",
        "\n",
        "\n",
        "# Handle missing values\n",
        "merged_df = merged_df.bfill().ffill().interpolate()\n",
        "\n",
        "# Display results\n",
        "print(merged_df.head())\n",
        "print(f\"✅ Final merged dataset shape: {merged_df.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Db6y3IPOOPO",
        "outputId": "2ecc5424-f846-402f-d8c0-41763db71bae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/surface_height.csv | Shape: (20379, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/zonal current.csv | Shape: (17468, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/vertical velocity at t points.csv | Shape: (17468, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/sea surface temperature.csv | Shape: (20379, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/dry blub temperature.csv | Shape: (140, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/potential temperature.csv | Shape: (17468, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/surface heigh.csv | Shape: (20379, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/salinity.csv | Shape: (17468, 4)\n",
            "✅ Loaded /content/drive/MyDrive/OceansLSTM/surface height on  t cell.csv | Shape: (17467, 4)\n",
            "               TIME              LON              LAT   surface_height  \\\n",
            "0 374.2420000000000 81.5000000000000 17.5000000000000 10.7213000000000   \n",
            "1 374.2420000000000 81.5000000000000 18.5000000000000 10.7213000000000   \n",
            "2 374.2420000000000 82.5000000000000 16.5000000000000 10.7213000000000   \n",
            "3 374.2420000000000 82.5000000000000 17.5000000000000 10.7213000000000   \n",
            "4 374.2420000000000 82.5000000000000 18.5000000000000 10.7213000000000   \n",
            "\n",
            "     zonal_current  vertical_velocity_at_t_points  sea_surface_temperature  \\\n",
            "0 -0.0345528000000               -0.0000039097800         26.6936000000000   \n",
            "1 -0.0345528000000               -0.0000039097800         26.6936000000000   \n",
            "2 -0.0345528000000               -0.0000039097800         26.6936000000000   \n",
            "3 -0.0345528000000               -0.0000039097800         26.6936000000000   \n",
            "4 -0.0345528000000               -0.0000039097800         26.6936000000000   \n",
            "\n",
            "   dry_blub_temperature  potential_temperature    surface_heigh  \\\n",
            "0       0.0000000000000       26.6936000000000 10.7213000000000   \n",
            "1       0.0000000000000       26.6936000000000 10.7213000000000   \n",
            "2       0.0000000000000       26.6936000000000 10.7213000000000   \n",
            "3       0.0000000000000       26.6936000000000 10.7213000000000   \n",
            "4       0.0000000000000       26.6936000000000 10.7213000000000   \n",
            "\n",
            "          salinity  surface_height_on__t_cell  \n",
            "0 27.5988000000000            0.7213450000000  \n",
            "1 27.5988000000000            0.7213450000000  \n",
            "2 27.5988000000000            0.7213450000000  \n",
            "3 27.5988000000000            0.7213450000000  \n",
            "4 27.5988000000000            0.7213450000000  \n",
            "✅ Final merged dataset shape: (75834, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.to_csv('/content/merged_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "syJHnyYePxsv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/merged_dataset.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a_MGJS0hP160",
        "outputId": "407a5876-94df-445e-af1e-2952843f6b30"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c45acfb6-994a-4c22-ad38-42289c139859\", \"merged_dataset.csv\", 7384509)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/merged_dataset.csv\")\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "df.iloc[:, 3:] = scaler.fit_transform(df.iloc[:, 3:])\n",
        "\n",
        "# Prepare data for LSTM\n",
        "sequence_length = 10  # Define sequence length\n",
        "features = df.iloc[:, 3:].values\n",
        "\n",
        "X, y = [], []\n",
        "for i in range(len(features) - sequence_length):\n",
        "    X.append(features[i:i + sequence_length])\n",
        "    y.append(features[i + sequence_length])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Define LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(sequence_length, X.shape[2])),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dense(X.shape[2])\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train model\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# Save model\n",
        "model.save(\"/mnt/data/lstm_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JsrIvowRjJt",
        "outputId": "00f3acb5-7e17-47fa-a701-5abd5b6148e9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 16ms/step - loss: 0.0098 - val_loss: 0.0011\n",
            "Epoch 2/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 6.9951e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 15ms/step - loss: 0.0013 - val_loss: 6.0551e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 5.8710e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - loss: 9.8413e-04 - val_loss: 5.3807e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 14ms/step - loss: 8.9101e-04 - val_loss: 5.3231e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15ms/step - loss: 8.2082e-04 - val_loss: 4.6682e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 15ms/step - loss: 7.5902e-04 - val_loss: 4.3036e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - loss: 7.1782e-04 - val_loss: 5.8915e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m2133/2133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 14ms/step - loss: 6.8223e-04 - val_loss: 4.7153e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_model.keras\")"
      ],
      "metadata": {
        "id": "Gx7JGFeYT46N"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}